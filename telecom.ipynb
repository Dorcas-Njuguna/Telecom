{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as p\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from seaborn import scatterplot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "database_name = 'telecom'\n",
    "table_name= 'xdr_data'\n",
    "\n",
    "connection_params = { \"host\": \"localhost\", \"user\": \"postgres\", \"password\": \"admin\",\n",
    "                    \"port\": \"5432\", \"database\": database_name}\n",
    "\n",
    "engine = create_engine(f\"postgresql+psycopg2://{connection_params['user']}:{connection_params['password']}@{connection_params['host']}:{connection_params['port']}/{connection_params['database']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data and screening it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str or SQLAlchemy Selectable (select or text object)\n",
    "sql_query = 'SELECT * FROM xdr_data'\n",
    "\n",
    "df = pd.read_sql(sql_query, con= engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get a concise summary of the dataset i.e. data types, missing data,..\n",
    "df.info()\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 10 rows of the dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returning a tuple with dimensions of the dataframe\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 sub tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the top 10 of handsets used by the customers.\n",
    "top_10_of_handsets =df['Handset Type'].value_counts().head(10)\n",
    "print(\"Top 10 Handsets:\")\n",
    "print(top_10_of_handsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the top 3 handset manufacturers by count\n",
    "top_3_manufacturers = df['Handset Manufacturer'].value_counts().head(3)\n",
    "\n",
    "print(\"Top 3 Handset Manufacturers:\")\n",
    "print(top_3_manufacturers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the top 5 handsets in each of the top three manufactures\n",
    "top_3_manufacturers = df['Handset Manufacturer'].value_counts().head(3).index.tolist()\n",
    "filtered_df = df[df['Handset Manufacturer'].isin(top_3_manufacturers)]\n",
    "top_5_handsets_per_manufacturer = filtered_df.groupby('Handset Manufacturer')['Handset Type'].value_counts().groupby('Handset Manufacturer').head(5)\n",
    "\n",
    "print(\"Top 5 Handsets per Top 3 of the Handset Manufacturers:\")\n",
    "print(top_5_handsets_per_manufacturer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the bottom 5 handsets in each of the bottom three manufactures\n",
    "bottom_3_manufacturers = df['Handset Manufacturer'].value_counts().tail(3).index.tolist()\n",
    "filtered_df = df[df['Handset Manufacturer'].isin(bottom_3_manufacturers)]\n",
    "bottom_5_handsets_per_manufacturer = filtered_df.groupby('Handset Manufacturer')['Handset Type'].value_counts().groupby('Handset Manufacturer').tail(5)\n",
    "\n",
    "print(\"Botttom 5 Handsets per bottom 3 of the Handset Manufacturers:\")\n",
    "print(bottom_5_handsets_per_manufacturer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation:\n",
    "# The most used handset is Huawei B528S-23A.  It is also the only handset from the Huawei Manufacturer that appears in the top 10 most used handsets.\n",
    "# I phone handsets seem to have the highest number of users as they take up 7 positions in top 10 mosted used handsets. \n",
    "# The top three handset manufacturers are Apple, Samsung, huawei respectively with each producing over 34400 handsets.\n",
    "# In each the top 3 manufacturers, the leading handset also appears in the top 10 of the most used handsets. Also, all the top 5 handsets in the manufacturer, Apple, also \n",
    "# appear in the top 10 most used handsets overall.\n",
    "\n",
    "# Recommendations:\n",
    "# The marketing team should consider partnering with the handset manufactures, in a mutually benefitting way, in order to give promotions to customers using the top 10 handsets to enhance customer retention.\n",
    "# They could also do the same for the least used handsets in order to broaden their customer base. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.1\n",
    "## Overview of the users behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# number of xDR sessions per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns pertaining to applications and user data\n",
    "user_app_columns = ['Bearer Id', 'Handset Manufacturer', 'Handset Type', 'Social Media DL (Bytes)',\n",
    "                    'Social Media UL (Bytes)', 'Google DL (Bytes)', 'Google UL (Bytes)',\n",
    "                    'Email DL (Bytes)', 'Email UL (Bytes)', 'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
    "                    'Netflix DL (Bytes)', 'Netflix UL (Bytes)', 'Gaming DL (Bytes)', 'Gaming UL (Bytes)',\n",
    "                    'Other DL (Bytes)', 'Other UL (Bytes)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_apps = df[user_app_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To count the number of xDR sessions per user\n",
    "\n",
    "df_user_apps['Number of xDR Sessions'] = df_user_apps.groupby('Bearer Id')['Bearer Id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the relevant columns for the result\n",
    "result_columns = ['Bearer Id', 'Number of xDR Sessions']\n",
    "\n",
    "result = df_user_apps[result_columns].drop_duplicates().reset_index(drop=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate session duration per user\n",
    "session_dur_per_user = df.groupby('Bearer Id')['Dur. (ms)'].sum().reset_index(name='Session Duration (ms)')\n",
    "\n",
    "print(session_dur_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the total download and upload data per user\n",
    "total_data_per_user =pd.DataFrame (df.groupby('Bearer Id')[['Total DL (Bytes)', 'Total UL (Bytes)']].sum().reset_index())\n",
    "\n",
    "print(total_data_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns related to applications\n",
    "application_columns = ['Bearer Id', 'Social Media DL (Bytes)', 'Social Media UL (Bytes)',\n",
    "                        'Google DL (Bytes)', 'Google UL (Bytes)', 'Email DL (Bytes)',\n",
    "                        'Email UL (Bytes)', 'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
    "                         'Netflix DL (Bytes)', 'Netflix UL (Bytes)', 'Gaming DL (Bytes)',\n",
    "                         'Gaming UL (Bytes)', 'Other DL (Bytes)', 'Other UL (Bytes)'\n",
    "                        \n",
    "                       ]\n",
    "\n",
    "# Aggregate the total data volume per user and application\n",
    "total_data_per_user_app = df[application_columns].groupby('Bearer Id').sum().reset_index()\n",
    "\n",
    "print(total_data_per_user_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: Index(['Bearer Id', 'Start ms', 'End ms', 'Dur. (ms)', 'IMSI', 'MSISDN/Number',\n",
      "       'IMEI', 'Avg RTT DL (ms)', 'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)',\n",
      "       'Avg Bearer TP UL (kbps)', 'TCP DL Retrans. Vol (Bytes)',\n",
      "       'TCP UL Retrans. Vol (Bytes)', 'DL TP < 50 Kbps (%)',\n",
      "       '50 Kbps < DL TP < 250 Kbps (%)', '250 Kbps < DL TP < 1 Mbps (%)',\n",
      "       'DL TP > 1 Mbps (%)', 'UL TP < 10 Kbps (%)',\n",
      "       '10 Kbps < UL TP < 50 Kbps (%)', '50 Kbps < UL TP < 300 Kbps (%)',\n",
      "       'UL TP > 300 Kbps (%)', 'HTTP DL (Bytes)', 'HTTP UL (Bytes)',\n",
      "       'Activity Duration DL (ms)', 'Activity Duration UL (ms)', 'Dur. (ms).1',\n",
      "       'Nb of sec with 125000B < Vol DL',\n",
      "       'Nb of sec with 1250B < Vol UL < 6250B',\n",
      "       'Nb of sec with 31250B < Vol DL < 125000B',\n",
      "       'Nb of sec with 37500B < Vol UL',\n",
      "       'Nb of sec with 6250B < Vol DL < 31250B',\n",
      "       'Nb of sec with 6250B < Vol UL < 37500B',\n",
      "       'Nb of sec with Vol DL < 6250B', 'Nb of sec with Vol UL < 1250B',\n",
      "       'Social Media DL (Bytes)', 'Social Media UL (Bytes)',\n",
      "       'Google DL (Bytes)', 'Google UL (Bytes)', 'Email DL (Bytes)',\n",
      "       'Email UL (Bytes)', 'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
      "       'Netflix DL (Bytes)', 'Netflix UL (Bytes)', 'Gaming DL (Bytes)',\n",
      "       'Gaming UL (Bytes)', 'Other DL (Bytes)', 'Other UL (Bytes)',\n",
      "       'Total UL (Bytes)', 'Total DL (Bytes)'],\n",
      "      dtype='object')\n",
      "Categorical Columns: Index(['Start', 'End', 'Last Location Name', 'Handset Manufacturer',\n",
      "       'Handset Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Creating separate dataframes for columns with numbers and objects.\n",
    "num_col = df.select_dtypes (include = ['number']).columns\n",
    "cat_col = df.select_dtypes (include = ['object']).columns\n",
    "\n",
    "df_num = df[num_col]\n",
    "df_cat = df[cat_col]\n",
    "\n",
    "print(\"Numerical Columns:\", num_col)\n",
    "print(\"Categorical Columns:\", cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in missing values with mean\n",
    "df_num = df_num.fillna(df_num.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "df_num.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing outliers with mean\n",
    "\n",
    "def replace_outliers_with_mean(df_num, threshold=3):\n",
    "    for col in df_num.columns:\n",
    "        z_scores = (df_num[col] - df_num[col].mean()) / df_num[col].std()\n",
    "        outlier_mask = (z_scores > threshold) | (z_scores < -threshold)\n",
    "        df_num[col][outlier_mask] = df_num[col].mean()\n",
    "    return df_num\n",
    "\n",
    "df_num = replace_outliers_with_mean(df_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic metrics\n",
    "df_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_num.corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "columns_to_plot = ['Dur. (ms)', 'Avg RTT DL (ms)',\n",
    "                   'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)',  \n",
    "                   'Social Media DL (Bytes)', 'Social Media UL (Bytes)',\n",
    "                    'Google DL (Bytes)', 'Google UL (Bytes)', 'Email DL (Bytes)',\n",
    "                    'Email UL (Bytes)', 'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
    "                    'Netflix DL (Bytes)', 'Netflix UL (Bytes)', 'Gaming DL (Bytes)',\n",
    "                    'Gaming UL (Bytes)', 'Other DL (Bytes)', 'Other UL (Bytes)']\n",
    "\n",
    "# Set up subplots\n",
    "num_plots = len(columns_to_plot)\n",
    "fig, axes = plt.subplots(nrows=num_plots, ncols=1, figsize=(10, 4 * num_plots))\n",
    "\n",
    "# Plot histograms for the columns\n",
    "for i, column in enumerate(columns_to_plot):\n",
    "    axes[i].hist(df_num[column], bins=20, color='skyblue', edgecolor='black')\n",
    "    axes[i].set_title(f'Histogram of {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_plot = ['Dur. (ms)', 'Avg RTT DL (ms)',\n",
    "                   'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)',\n",
    "                   'Social Media DL (Bytes)', 'Social Media UL (Bytes)',\n",
    "                   'Google DL (Bytes)', 'Google UL (Bytes)', 'Email DL (Bytes)',\n",
    "                   'Email UL (Bytes)', 'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
    "                   'Netflix DL (Bytes)', 'Netflix UL (Bytes)', 'Gaming DL (Bytes)',\n",
    "                   'Gaming UL (Bytes)', 'Other DL (Bytes)', 'Other UL (Bytes)']\n",
    "\n",
    "# Set up subplots\n",
    "num_plots = len(columns_to_plot)\n",
    "fig, axes = plt.subplots(nrows=num_plots, ncols=1, figsize=(10, 4 * num_plots))\n",
    "\n",
    "# Plot box plots for the columns\n",
    "for i, column in enumerate(columns_to_plot):\n",
    "    axes[i].boxplot(df_num[column])\n",
    "    axes[i].set_title(f'Box Plot of {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Value')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num['Total Bytes Sum'] = df_num['Total DL (Bytes)'] + df_num['Total UL (Bytes)']\n",
    "print(df_num['Total Bytes Sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the social media columns and find their correlations to the Total Bytes\n",
    "\n",
    "application_columns2 = ['Social Media DL (Bytes)', 'Social Media UL (Bytes)',\n",
    "                        'Google DL (Bytes)', 'Google UL (Bytes)', 'Email DL (Bytes)',\n",
    "                        'Email UL (Bytes)', 'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
    "                         'Netflix DL (Bytes)', 'Netflix UL (Bytes)', 'Gaming DL (Bytes)',\n",
    "                         'Gaming UL (Bytes)', 'Other DL (Bytes)', 'Other UL (Bytes)'\n",
    "                        \n",
    "                       ]\n",
    "\n",
    "\n",
    "correlations = df_num[application_columns2 + ['Total Bytes Sum']]. corr()\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for app_column in application_columns2:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x='Total Bytes Sum', y=app_column, data=df_num)  \n",
    "    plt.title(f'Scatter Plot: {app_column} vs Total Bytes Sum')\n",
    "    plt.xlabel('Total Bytes Sum')\n",
    "    plt.ylabel(app_column)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_num[application_columns2 + ['Total Bytes Sum']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.show()      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num['Total Duration'] = df_num['Dur. (ms)']\n",
    "\n",
    "# Creating decile classes based on total duration.\n",
    "df_num['Duration Decile'] = pd.qcut(df_num['Total Duration'], q=[0, 0.2, 0.4, 0.6, 0.8, 1], labels=False, precision=0)\n",
    "\n",
    "# Group by 'MSISDN/Number' and 'Duration Decile', then compute the sum of 'Total Bytes Sum' for each group\n",
    "decile_totals = df_num.groupby(['MSISDN/Number', 'Duration Decile'])['Total Bytes Sum'].sum().reset_index()\n",
    "\n",
    "# Get the top five decile classes\n",
    "top_five_deciles = decile_totals.groupby('Duration Decile')['Total Bytes Sum'].sum().nlargest(5).index\n",
    "\n",
    "# Filter the DataFrame for the top five decile classes\n",
    "top_five_deciles_data = decile_totals[decile_totals['Duration Decile'].isin(top_five_deciles)]\n",
    "\n",
    "# Display the result\n",
    "print(top_five_deciles_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the DataFrame with the application columns.\n",
    "subset_df = df_num[application_columns2]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = subset_df.corr\n",
    "\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "programmingexpert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
